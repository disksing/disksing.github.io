---
title: "如何快速检测新冠病毒"
date: 2020-06-16
tags: ["算法", "杂谈"]
---

这几天，北京迎来了第二波新冠疫情。由于这一波疫情爆发在人流量大而密集的新发地市场，感染人群的排查上也遇到了严峻挑战。其中一个很突出的问题就是北京市每天能承载的核酸检测量是有限的，无法承受大量检测需求带来的冲击。

{{< figure src="/assets/img/ncov-testing.jpg" title="核酸检查72小时才能出结果的通知" style="text-align:center" >}}

联想到之前[武汉10天检测了1000万人](https://www.yicai.com/news/100626921.html)的新闻，平均每天的检查量是恐怖的 100 万。在当时也有一些报道，介绍了检测方式是把多份样本混合在一起进行检测，从而总体上增快了检测速度。

混检的原理是这样的，把多个人的样本混合在一起送到实验室进行核酸扩增检测，如果样本没有被检测出病毒，那么说明这些人都没有被感染，反之说明这些人中至少有一个人被感染，再对这些疑似人群再进行第二轮检查（不多人样本混合）。在感染比例不高的情况下，只有极少数的人需要检查第二轮，因此总体上大大减少了实验室需要检查的样本数量，提升了检测速度。

根据之前流传的小道消息，这次北京待检测的总人数可能有几十万之多。这个消息不一定准确，不过根据官方公开的资料，北京[一天的检查数量是 70000 多](http://www.xinhuanet.com/politics/2020-06/15/c_1126115537.htm)，加上上面的图片说需要等 3 天才能出检测结果，也算是侧面验证了总检测量几十万人的说法。

那么，如果北京这一次也参照武汉的方式进行样本混合检测，是否会是更好的选择呢？

为了简化讨论，我们假设北京需要检测的总人数是 30 万，每天最大能承载的检测量是 10 万，阳性比例我们假定是 0.1%，也就是说有共约 300 人感染。

我们用下面几个指标来评价检测方法的优劣，好的检测方法应该要能：

- **尽快找到感染人群。**
- **尽快排除未感染的疑似人群。**
- **使用尽量少的总检查样本数。**

先来看一人一样本的传统方法。检查完 30 万人需要满负荷检测 3 天，平均每天检出 100 人，总检测量是 30 万。

/ | Day0 | Day1 | Day2 | Day3
-- | --- | --- | --- | ---
确诊 | 0 | 100 | 200 | 300
疑似 | 300,000 | 200,000 | 100,000 | 0
总检测 | 0 | 100,000 | 200,000 | 300,000

再来看使用样本混合的方法。根据现有资料，[专家建议混检不宜超过 10 人样本](https://www.yicai.com/news/100631887.html)，我们就以每 10 人样本混合来分析。

第一天采集所有 30 万人的样本，并混合成 3 万个瓶子，其中有 300 个瓶子会被检测出病毒（注：这里忽略掉多个感染样本混入一个瓶子的情况），这 300 个瓶子对应的 3000 人就是第一天查完之后的疑似。

/ | Day0 | Day1 | Day2
-- | --- | --- | ---
确诊 | 0 | 0 | 300
疑似 | 300,000 | 3,000 | 0
总检测 | 0 | 30,000 | 33,000

这个方法比前一种要好。它提前 1 天排查出全部 300 个病例，第二就能将疑似降到 3000 人的水平，这对尽早进行流行病学排查和防控非常有利，而且总体检测量只有前者的约 1/10，节约了实验室的成本和压力。

唯一的弱点是第一天结束时确诊是 0，不利于快速对确诊人群进行管理和隔离，不过疑似人数缩小到了 3000 人的规模，也算是对这点不足起到一点补偿了。

那么有没有更好的方法呢？

我联想到了计算机领域的一种常用数据结构，叫 [Bloom Filter](https://zh.wikipedia.org/wiki/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8)。比如数据库里的存储引擎，常常就用这个数据结构来判断要查询的 key 是不是不存在。方法是准备多个数组，对于数据库里的每一个 key，都用多个散列函数进行 hash，根据 hash 出来的值把数组对应下标置成 1。查询时，只要把要查的 key 给 hash 一下，然后看对应的数组位置是不是 1，如果有一个为 0，那就说明这个 key 不存在，如果全都 1，说明这个 key 很可能存在。

对应到病毒检测，是这样的：准备 6 万个瓶子，分成 2 组，每组 3 万个。采集样本时，每人采集 2 份，同时给每个人随机分配 2 个 1~30000 的编号，再把两个样本分别扔进对应编号的瓶子里。30 万人采集完了以后，恰好每个瓶子混了 10 个样本，然后全部送进实验室检查。

第二天检测结果出来后，再根据之前记录的每个人的 2 个编号去看对应的瓶子，如果 2 个瓶子都是阳性，那么这个人很可能感染了，但是如果 2 个瓶子有一个是阴性，那就说明这个人肯定没感染。

我们来分析一下误报率，也就是一个没被感染的人，被判断出可能感染的概率。总感染人数是 300，因此每组 30000 个瓶子中能检测出病毒的最多只有 300 个（当感染样本投进同一个瓶子时会更少），也就是说每组中只有不超过 1% 的瓶子能检出病毒。于是，对于一个没有被感染的人，他的 2 个样本都被投入有病毒的瓶子的概率不会超过 1%x1% = 0.01%，大约是 30 人。

那么，第三种方法的效果就是，第一天就把疑似范围缩小为约 330，这对尽早进行排查防控极为有利，实践中可以直接当作确诊来处理。其中约有 10% 是误判的，第二天再对这 330 人重复检测一次即可。

/ | Day0 | Day1 | Day2
-- | --- | --- | --- 
确诊 | 0 | 0 | 300
疑似 | 300,000 | 330 | 0
总检测 | 0 | 60,000 | 60,330

总体来看，第三种方法要优于前两种，希望有关部门在后续的检测中采纳！
