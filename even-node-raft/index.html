<!doctype html><html lang=zh-cn><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>偶数节点 raft</title><link rel=icon href=http://disksing.com/favicon.png><style>html body{font-family:noto serif sc,sans-serif;background-color:#fff}:root{--accent: red;--border-width:  5px }</style><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Noto%20Serif%20SC"><link rel=stylesheet href=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css integrity=sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u crossorigin=anonymous><link rel=stylesheet href=https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css integrity=sha384-wvfXpqpZZVQGK6TAh5PVlGOfQNHSoD2xbE+QkPxCAFlNEevoEH3Sl0sibVcOQVnN crossorigin=anonymous><link rel=stylesheet href=/css/main.css><script src=https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js></script><script src=https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js integrity=sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa crossorigin=anonymous></script><script>$(document).on('click',function(){$('.collapse').collapse('hide');})</script><meta name=generator content="Hugo 0.80.0"><script async src="https://www.googletagmanager.com/gtag/js?id=UA-154774927-1"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)};gtag('js',new Date());gtag('config','UA-154774927-1');</script><script type=text/javascript async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script data-ad-client=ca-pub-8963356574249468 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body><nav class="navbar navbar-default navbar-fixed-top"><div class=container><div class=navbar-header><a class="navbar-brand visible-xs" href=#>偶数节点 raft</a>
<button class=navbar-toggle data-target=.navbar-collapse data-toggle=collapse>
<span class=icon-bar></span><span class=icon-bar></span><span class=icon-bar></span></button></div><div class="collapse navbar-collapse"><ul class="nav navbar-nav"><li><a href=/>主页</a></li><li><a href=/post/>文章</a></li><li><a href=/tip/>知识点</a></li><li><a href=/project/>开源项目</a></li><li><a href=/activity/>动态</a></li><li><a href=/about/>关于</a></li></ul><ul class="nav navbar-nav navbar-right"><li class=navbar-icon><a href=mailto:i@disksing.com><i class="fa fa-envelope-o"></i></a></li><li class=navbar-icon><a href=https://github.com/disksing/><i class="fa fa-github"></i></a></li><li class=navbar-icon><a href=http://weibo.com/539523448><i class="fa fa-weibo"></i></a></li><li class=navbar-icon><a href="http://shang.qq.com/wpa/qunwpa?idkey=ade2895067e4105ce59e0c56863d650543b4448245f179574c6684fe1cb7b5d5"><i class="fa fa-qq"></i></a></li><li class=navbar-icon><a href=https://space.bilibili.com/2207710><i class="fa fa-tv"></i></a></li><li class=navbar-icon><a href=https://twitter.com/disksing/><i class="fa fa-twitter"></i></a></li></ul></div></div></nav><main><div><h1>偶数节点 raft</h1><h5>2020-01-31</h5><a href=http://disksing.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F><kbd class=item-tag>分布式系统</kbd></a>
<a href=http://disksing.com/tags/%E5%85%B1%E8%AF%86%E7%AE%97%E6%B3%95><kbd class=item-tag>共识算法</kbd></a>
<a href=http://disksing.com/tags/raft><kbd class=item-tag>raft</kbd></a></div><div align=start class=content><p>对 raft 有所了解的同学都知道，raft 一般会使用奇数个节点，比如 3，5，7 等等。这是因为 raft 是 一种基于多节点投票选举机制的共识算法，通俗地说，只有超过半数节点在线才能提供服务。这里<em>超过半数</em>的意思是<em><strong>N/2+1</strong></em>（而不是<em>N/2</em>），举例来说，3 节点集群需要 2 个以上节点在线，5 节点集群需要 3 个以上节点在线，等等。对于偶数节点的集群，2 节点集群需要 2 节点同时在线，4 节点集群需要 3 节点在线，以此类推。实际上不只是 raft，所有基于 Quorum 的共识算法大体上都是这么个情况，例如 Paxos，ZooKeeper 什么的，本文仅以 raft 为例讨论。</p><p>先考察一下为什么 raft 通常推荐使用奇数节点而不是偶数节点。</p><p>共识算法要解决的核心问题是什么呢？是分布式系统中单个节点的不可靠造成的不可用或者数据丢失。raft 保存数据冗余副本来解决这两个问题，当少数节点发生故障时，剩余的节点会自动重新进行 leader 选举（如果需要）并继续提供服务，而且 log replication 流程也保证了剩下的节点（构成 Quorum）总是包含了故障前成功写入的最新数据，因此也不会发生数据丢失。</p><p>我们对比一下 3 节点的集群和 4 节点的集群，Quorum 分别是 2 和 3，它们能容忍的故障节点数都是 1。如果深究的话，从概率上来说 4 节点集群发生 2 节点同时故障的可能性要更高一些。于是我们发现，相对于 3 节点集群，4 节点集群消耗更多的硬件资源，却换来了更差的可用性，显然不是个好选择。</p><p>但是！！！</p><p>上面说了，raft 解决的核心问题有两个，分别是高可用和数据容灾。跟奇数节点相比，偶数节点的方案从可用性上看很不划算，但是数据容灾方面却是有优势的。还是以 4 节点为例，因为 Quorum 是 3，写入数据的时候需要复制到至少 3 个节点才算写入成功，假如此时有 2 个节点同时故障，这种情况下虽然不可用了，但是剩余的两个节点一定包含有最新的数据，因此没有发生数据丢失。这一点很容易被忽视，在常见的奇数节点配置下，保证可用和保证数据不丢所容忍的故障节点数是重合的，但是在偶数节点配置下是不一样的。</p><p>根据上面的分析，偶数节点集群的适用场景是“能容忍一定时间的不可用，但不能容忍数据丢失”，应该有不少严肃的金融场景是符合这个描述的，毕竟一段时间不服务也比丢掉数据要强呀。</p><p>下面以两数据中心环境为例来对比一下。限制条件是任意一个数据中心故障时（比如发生严重自然灾害），能容忍一定时间的不可用，但不允许发生数据丢失。</p><p>如果使用奇数节点集群配置，两个数据中心的节点数一定是不对等的，一旦节点数更多的那个数据中心故障，就可能发生数据丢失了。而如果使用偶数节点配置，两个数据中心的节点数是一样的，任意一个数据中心故障后，另一个数据中心一定包含有最新数据，我们只需要使用工具改写 raft 元信息，让剩余数据中心的所有节点组成新的 raft group 并使得 Quorum 恰好等于剩余节点数，raft 选举机制将会自动选择包含有最新数据的节点当 leader 并恢复服务。</p><hr><p>题外话：本来想在 etcd 上实践下这套方案，可惜最后一步 etcd 恢复数据的时候只支持从单一节点恢复，所以无法做到“自动选择包含有最新数据的节点当 leader 并恢复服务”。我<a href=https://github.com/etcd-io/etcd/issues/11486>给 etcd 提了个 issue</a> 不过貌似并没有成功让他们了解到我想干啥，如果有人看到这里觉得这事情有搞头的话，可以帮忙去 issue 下支持一下。。。</p></div><hr><b>欢迎加入技术讨论 QQ 群：</b> 481269635 （硬盘在歌唱）<h4 class=page-header>Comments</h4><div id=disqus_thread></div><script type=application/javascript>var disqus_config=function(){};(function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById('disqus_thread').innerHTML='Disqus comments not available by default when the website is previewed locally.';return;}
var d=document,s=d.createElement('script');s.async=true;s.src='//'+"disksing"+'.disqus.com/embed.js';s.setAttribute('data-timestamp',+new Date());(d.head||d.body).appendChild(s);})();</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a><h4 class=page-header>Related</h4><div class=item><h4><a href=/truetime/>TrueTime和原子钟</a></h4><h5>2021-02-10</h5><a href=http://disksing.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F><kbd class=item-tag>分布式系统</kbd></a>
<a href=http://disksing.com/tags/tidb><kbd class=item-tag>TiDB</kbd></a></div><div class=item><h4><a href=/paxos/>Paxos从入门到学会Raft</a></h4><h5>2020-10-20</h5><a href=http://disksing.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F><kbd class=item-tag>分布式系统</kbd></a>
<a href=http://disksing.com/tags/%E5%85%B1%E8%AF%86%E7%AE%97%E6%B3%95><kbd class=item-tag>共识算法</kbd></a>
<a href=http://disksing.com/tags/raft><kbd class=item-tag>raft</kbd></a>
<a href=http://disksing.com/tags/paxos><kbd class=item-tag>paxos</kbd></a></div><div class=item><h4><a href=/txn-commit-point/>分布式事务的 Commit Point</a></h4><h5>理解分布式事务原子性（atomic）的关键所在</h5><a href=http://disksing.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93><kbd class=item-tag>数据库</kbd></a>
<a href=http://disksing.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F><kbd class=item-tag>分布式系统</kbd></a>
<a href=http://disksing.com/tags/tidb><kbd class=item-tag>TiDB</kbd></a></div></main><footer></footer><p class="copyright text-muted">&copy; 2014-2021 ALL RIGHTS RESERVED
|
本站由 <a href=https://gohugo.io>Hugo</a> 和 <a href=https://github.com/calintat/minimal>Minimal</a> 强力驱动
|
<a href=http://disksing.com/post/index.xml target=_blank><i class="fa fa-rss-square"></i>订阅本站文章</a> <a href=http://github.com/disksing/disksing.github.io/issues/new target=_blank><i class="fa fa-bug"></i>反馈问题</a><br>若无特别说明，本站文章采用 <a rel=license href=http://creativecommons.org/licenses/by/4.0/>CC BY 4.0</a> 进行许可，文中涉及代码采用 <a rel=license href=http://creativecommons.org/publicdomain/zero/1.0/>CC0 1.0 Universal</a> 进行许可</p><script>MathJax={tex:{inlineMath:[['$','$']],displayMath:[['$$','$$']]},svg:{fontCache:'global'}};</script><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js></script></body></html>